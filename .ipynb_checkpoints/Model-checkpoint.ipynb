{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571f5143",
   "metadata": {},
   "source": [
    "## Import Packages and Reading of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3a18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import shap\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb # recommended version: 1.5.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from xgboost import plot_importance\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d139119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading of Excel\n",
    "dataset = pd.read_csv('cleaned_others_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d544eda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>un_no_of_char</th>\n",
       "      <th>un_special_char</th>\n",
       "      <th>un_uppercase</th>\n",
       "      <th>name_no_of_char</th>\n",
       "      <th>name_special_char</th>\n",
       "      <th>name_uppercase</th>\n",
       "      <th>des_no_of_usertags</th>\n",
       "      <th>des_no_of_hashtags</th>\n",
       "      <th>des_external_links</th>\n",
       "      <th>has_description</th>\n",
       "      <th>account_age_in_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>17090</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>785</td>\n",
       "      <td>829</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>1232</td>\n",
       "      <td>1469</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "      <td>838</td>\n",
       "      <td>2518</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>737048</td>\n",
       "      <td>128</td>\n",
       "      <td>4739</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>367523</td>\n",
       "      <td>17291</td>\n",
       "      <td>24084</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>492</td>\n",
       "      <td>21437</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>618</td>\n",
       "      <td>3021</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35697</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>803247</td>\n",
       "      <td>7</td>\n",
       "      <td>3159</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35698 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protected  verified  location  followers_count  following_count  \\\n",
       "0              0         0         0             1997                5   \n",
       "1              0         0         1              785              829   \n",
       "2              0         0         0              243             1232   \n",
       "3              0         0         1              749              838   \n",
       "4              0         1         1           737048              128   \n",
       "...          ...       ...       ...              ...              ...   \n",
       "35693          0         1         1           367523            17291   \n",
       "35694          0         0         1               14                0   \n",
       "35695          0         0         0              395              492   \n",
       "35696          0         0         0              159              618   \n",
       "35697          0         1         1           803247                7   \n",
       "\n",
       "       tweet_count  isFraud  un_no_of_char  un_special_char  un_uppercase  \\\n",
       "0            17090        1             15                1             0   \n",
       "1              251        0             12                0             1   \n",
       "2             1469        0              8                0             1   \n",
       "3             2518        0             11                0             1   \n",
       "4             4739        0             13                0             1   \n",
       "...            ...      ...            ...              ...           ...   \n",
       "35693        24084        0             14                0             1   \n",
       "35694          238        0              8                1             1   \n",
       "35695        21437        1             14                0             1   \n",
       "35696         3021        0              8                0             1   \n",
       "35697         3159        0              9                1             1   \n",
       "\n",
       "       name_no_of_char  name_special_char  name_uppercase  des_no_of_usertags  \\\n",
       "0                   19                  0               1                   2   \n",
       "1                    8                  0               1                   0   \n",
       "2                   11                  0               0                   0   \n",
       "3                   15                  0               1                   0   \n",
       "4                   14                  0               1                   1   \n",
       "...                ...                ...             ...                 ...   \n",
       "35693               10                  0               1                   2   \n",
       "35694                8                  0               1                   0   \n",
       "35695               16                  0               1                   0   \n",
       "35696               14                  0               1                   0   \n",
       "35697               10                  1               0                   0   \n",
       "\n",
       "       des_no_of_hashtags  des_external_links  has_description  \\\n",
       "0                       0                   0                1   \n",
       "1                       0                   0                1   \n",
       "2                       0                   0                1   \n",
       "3                       0                   0                1   \n",
       "4                       0                   0                1   \n",
       "...                   ...                 ...              ...   \n",
       "35693                   0                   0                1   \n",
       "35694                   0                   0                1   \n",
       "35695                   0                   0                1   \n",
       "35696                   0                   0                0   \n",
       "35697                   0                   0                0   \n",
       "\n",
       "       account_age_in_days  \n",
       "0                     2184  \n",
       "1                     2159  \n",
       "2                     1939  \n",
       "3                     2270  \n",
       "4                     3919  \n",
       "...                    ...  \n",
       "35693                 4704  \n",
       "35694                 4289  \n",
       "35695                 3792  \n",
       "35696                 2659  \n",
       "35697                 3860  \n",
       "\n",
       "[35698 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b40aae",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "* Scale numerical features\n",
    "* One Hot Encode for categorical/ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70acbf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (28558, 17) (28558,)\n",
      "Test set: (7140, 17) (7140,)\n"
     ]
    }
   ],
   "source": [
    "# Getting X and y\n",
    "x = dataset.drop(columns = ['isFraud'])\n",
    "y = dataset['isFraud']\n",
    "\n",
    "# Split into training and testing sets before scaling the variables and performing one hot encoding to avoid data leakage\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=101)\n",
    "print(\"Train set:\", x_train.shape, y_train.shape)\n",
    "print(\"Test set:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We only want to scale the numeric variables and not the categorical features. \n",
    "# # Hence, we create a columntransformer to help us to do this\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# x_train[['followers_count', 'following_count', 'tweet_count', 'un_no_of_char', 'name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags']] = scaler.fit_transform(x_train[['followers_count', 'following_count', 'tweet_count', 'un_no_of_char','name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags']])\n",
    "\n",
    "# x_test[['followers_count', 'following_count', 'tweet_count', 'un_no_of_char', 'name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags']] = scaler.transform(x_test[['followers_count', 'following_count', 'tweet_count', 'un_no_of_char','name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags']])\n",
    "\n",
    "# # Transform the year column into a categorical variable and store the result in a dataframe\n",
    "# encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "# transformed_year_train_matrix = encoder.fit_transform(x_train[['year']])\n",
    "# transformed_year_train = pd.DataFrame(transformed_year_train_matrix, columns = encoder.get_feature_names())\n",
    "\n",
    "# # Using the fitted encoder to transform the test data and storing in a dataframe\n",
    "# transformed_year_test_matrix = encoder.transform(x_test[['year']])\n",
    "# transformed_year_test = pd.DataFrame(transformed_year_test_matrix, columns = encoder.get_feature_names())\n",
    "\n",
    "# # Reset the index for training and testing sets to allow merging with the one hot encoded variables\n",
    "# # Drop the index column \n",
    "# x_train.reset_index(inplace = True, drop = True)\n",
    "# x_test.reset_index(inplace = True, drop = True)\n",
    "# y_train.reset_index(drop = True, inplace = True)\n",
    "# y_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# # Combine the scaled numeric variables together with the year categorical variables\n",
    "# x_train = pd.concat([x_train, transformed_year_train], axis = 1)\n",
    "# x_test = pd.concat([x_test, transformed_year_test], axis = 1)\n",
    "\n",
    "# # Drop the year column since we already have the dummy variables for year\n",
    "# x_train.drop(labels = ['year'], axis = 1, inplace = True)\n",
    "# x_test.drop(labels = ['year'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6a8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that combines all the preprocessing steps (for model pipeline purpose)\n",
    "class ExperimentalTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, numeric_variables = ['followers_count', 'following_count', 'tweet_count', 'un_no_of_char','name_no_of_char', 'des_no_of_usertags', 'des_no_of_hashtags', 'account_age_in_days']):\n",
    "        self.encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "        self.scaler = StandardScaler()\n",
    "        #specified numeric variables, by default it is the above\n",
    "        self.numeric_variables = numeric_variables\n",
    "        self.columns = []\n",
    "    \n",
    "    #The fit function that will be called when this custom transformer is fit\n",
    "    def fit(self, X, y = None):\n",
    "        #fit the one hot encoder to the year\n",
    "#         self.encoder.fit(X[['year']])\n",
    "        #fit the scaler on the numeric variables\n",
    "        self.scaler.fit(X[self.numeric_variables])\n",
    "        return self\n",
    "    \n",
    "    #The transform function that will be called\n",
    "    def transform(self, X, y = None):\n",
    "        \n",
    "        #to avoid changing the original dataset\n",
    "        X_ = X.copy()\n",
    "        #transforming the numeric variables according to the fitted scaler\n",
    "        X_[self.numeric_variables] = self.scaler.transform(X_[self.numeric_variables])\n",
    "        \n",
    "#         #next, create a date matrix using the fitted encoder\n",
    "#         transformed_year_matrix = self.encoder.transform(X_[['year']])\n",
    "#         #get the dataframe\n",
    "#         year_cols = list(map(lambda year: year.replace('x0', 'year'), self.encoder.get_feature_names()))\n",
    "#         transformed_year_train = pd.DataFrame(transformed_year_matrix, columns = year_cols)\n",
    "#         #reset the index of the original dataframe\n",
    "#         X_.reset_index(drop = True, inplace = True)\n",
    "#         X_ = pd.concat([X_, transformed_year_train], axis = 1)\n",
    "#         #drop the year column from the dataframe\n",
    "#         X_.drop(labels = ['year'], inplace = True, axis = 1)\n",
    "        self.columns = X_.columns\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94b9fe",
   "metadata": {},
   "source": [
    "## Charts and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74dafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_chart(shap_values, x_test_values, names, model_type):\n",
    "# #     feature_importance_df = pd.DataFrame(model.coef_.T, x_train.columns.T,columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "# #     fig = feature_importance_df.plot(kind=\"barh\", figsize=(20, 50))\n",
    "# #     bg = fig.patch\n",
    "# #     plt.gca().invert_yaxis()\n",
    "#     shap.summary_plot(shap_values, x_test_values, feature_names = names, plot_type = \"bar\", sort = True)\n",
    "#     plt.grid()\n",
    "# #     plt.savefig(f'Charts\\\\{model_type} Feature Importance.png', dpi=300)\n",
    "#     plt.show()\n",
    "\n",
    "# model = SVC()\n",
    "# model.fit(x_train, y_train)\n",
    "# explainer = shap.Explainer(model.predict, x_test, feature_perturbation=\"interventional\")\n",
    "# shap_values = explainer(x_test)\n",
    "# x_test_arr = x_test.toarray()\n",
    "# feature_chart(shap_values, x_test_arr, x_test.columns, model_type)\n",
    "    \n",
    "def feature_chart(feature_importance_df, model_type):\n",
    "#     feature_importance_df = pd.DataFrame(model.coef_.T, x_train.columns.T,columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "    fig = feature_importance_df.plot(kind=\"barh\", figsize=(12, 15))\n",
    "    bg = fig.patch\n",
    "    bg.set_facecolor(\"white\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid()\n",
    "#     plt.savefig(f'Charts\\\\{model_type} Feature Importance.png', dpi=300, facecolor=fig.get_facecolor())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba0b92",
   "metadata": {},
   "source": [
    "## 00 Baseline\n",
    "* Model \n",
    "* Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "baseline = DummyClassifier(strategy = \"uniform\", \n",
    "                           random_state = 123)\n",
    "transformer = ExperimentalTransformer()\n",
    "baseline_pipeline = make_pipeline(transformer, baseline)\n",
    "baseline_model = baseline_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8db93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction\n",
    "y_pred = baseline_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e922e",
   "metadata": {},
   "source": [
    "## 01 Logistic Regression\n",
    "* Model \n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ea5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "log_regression = LogisticRegression()\n",
    "transformer = ExperimentalTransformer()\n",
    "log_model_pipeline = make_pipeline(transformer, log_regression)\n",
    "log_model = log_model_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b30e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# filename = '01 Logistic Regression.sav'\n",
    "# pickle.dump(log_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# results_random = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-Squared\n",
    "log_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction\n",
    "y_pred = log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23963f",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcde3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature = pd.DataFrame(log_model.named_steps[\"logisticregression\"].coef_.T, log_model.named_steps[\"experimentaltransformer\"].columns, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9913e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_chart(feature, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1fe58",
   "metadata": {},
   "source": [
    "## 02 Random Forest\n",
    "* Model (Random Search + Grid Search)\n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc165c",
   "metadata": {},
   "source": [
    "### Model (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96628df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "rf_classifier = RandomForestClassifier()\n",
    "transformer = ExperimentalTransformer()\n",
    "rf_model = make_pipeline(transformer, rf_classifier)\n",
    "\n",
    "space = dict()\n",
    "\n",
    "# Number of trees in random forest\n",
    "space[\"randomforestclassifier__n_estimators\"] = [10, 50, 200, 600, 800, 1200]\n",
    "\n",
    "# Number of features to consider at every split (this parameter avoids overfitting by limiting how many features each leaf node can look at) \n",
    "space[\"randomforestclassifier__max_features\"] = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree (how deep the tree goes)\n",
    "space[\"randomforestclassifier__max_depth\"] = [None, 10, 40, 80, 120]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "space[\"randomforestclassifier__min_samples_split\"] = [2, 10, 40, 100]\n",
    "\n",
    "# Method of selecting samples for training each tree (bootstrap sampling or not)\n",
    "space[\"randomforestclassifier__bootstrap\"] = [True, False]\n",
    "\n",
    "# Define search\n",
    "random_search = RandomizedSearchCV(rf_model, \n",
    "                                   space, \n",
    "                                   scoring = 'f1',\n",
    "                                   cv = 5, \n",
    "                                   verbose = 2, \n",
    "                                   random_state = 123, \n",
    "                                   n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_random_rf = random_search.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# filename = '02 Random Forest (random).sav'\n",
    "# pickle.dump(results_random, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# results_random = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "print('Best Score: %s' % results_random_rf.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using RandomSearchCV\n",
    "y_pred_random = results_random_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_random)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_random)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_random)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_random)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_random)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_random)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333b817",
   "metadata": {},
   "source": [
    "### Model (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "rf_classifier = RandomForestClassifier()\n",
    "transformer = ExperimentalTransformer()\n",
    "rf_model = make_pipeline(transformer, rf_classifier)\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "# Number of trees in random forest\n",
    "grid[\"randomforestclassifier__n_estimators\"] = [10, 50, 200, 600, 800, 1200]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "grid[\"randomforestclassifier__max_features\"] = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree (how deep the tree goes)\n",
    "grid[\"randomforestclassifier__max_depth\"] = [None, 10, 40, 80, 120]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "grid[\"randomforestclassifier__min_samples_split\"] = [2, 10, 40, 100]\n",
    "\n",
    "# Method of selecting samples for training each tree (bootstrap sampling or not)\n",
    "grid[\"randomforestclassifier__bootstrap\"] = [True, False]\n",
    "\n",
    "# Define search\n",
    "grid_search = GridSearchCV(rf_model, \n",
    "                           grid, \n",
    "                           scoring = 'f1',\n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_grid_rf = grid_search.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# filename = '02 Random Forest (grid).sav'\n",
    "# pickle.dump(results_grid, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# results_grid = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "print('Best Score: %s' % results_grid_rf.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using GridSearchCV\n",
    "y_pred_grid = results_grid_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4116fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_grid)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_grid)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_grid)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_grid)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_grid)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_grid)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fa204",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa153269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search:\", results_grid_rf.best_score_) \n",
    "print(\"Randomised Search:\", results_random_rf.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by grid search)\n",
    "params_rf = results_grid_rf.best_params_\n",
    "\n",
    "rf_classifier = RandomForestClassifier(bootstrap = params_rf[\"randomforestclassifier__bootstrap\"], \n",
    "                                       max_depth = params_rf[\"randomforestclassifier__max_depth\"], \n",
    "                                       max_features = params_rf[\"randomforestclassifier__max_features\"], \n",
    "                                       min_samples_split = params_rf[\"randomforestclassifier__min_samples_split\"], \n",
    "                                       n_estimators = params_rf[\"randomforestclassifier__n_estimators\"])\n",
    "\n",
    "transformer = ExperimentalTransformer()\n",
    "rf_model_pipeline = make_pipeline(transformer, rf_classifier)\n",
    "rf_model = rf_model_pipeline.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "# Save the model to disk\n",
    "# filename = '02 Random Forest (Optimal).sav'\n",
    "# pickle.dump(rf_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# rf_regression = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bda1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_optimal = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9affb9b",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81edf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model.feature_importances_\n",
    "feature = pd.DataFrame(rf_model.named_steps[\"randomforestclassifier\"].feature_importances_, rf_model.named_steps[\"experimentaltransformer\"].columns.T, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_chart(feature, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32988753",
   "metadata": {},
   "source": [
    "## 03 XGBoost\n",
    "* Model (Random Search + Grid Search + Bayesian Optimisation)\n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410e8c7",
   "metadata": {},
   "source": [
    "### Model (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a026d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train = y_train.value_counts()[0] / y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e516bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(gamma = 0.1,\n",
    "                                   alpha = 0.5,\n",
    "                                   scale_pos_weight = weight_train,\n",
    "                                   objective = \"binary:logistic\",\n",
    "                                   eval_metric = \"logloss\")\n",
    "transformer = ExperimentalTransformer()\n",
    "xgb_model = make_pipeline(transformer, xgb_classifier)\n",
    "\n",
    "space = dict()\n",
    "\n",
    "# Maximum depth of the individual regression estimators\n",
    "space[\"xgbclassifier__max_depth\"] = [6, 10, 15, 20, 25]\n",
    "\n",
    "# Fraction of samples to be used for fitting the individual base learners\n",
    "space[\"xgbclassifier__subsample\"] = [0.6, 0.8, 1.0]\n",
    "\n",
    "# Step size shrinkage used in update to prevents overfitting\n",
    "space[\"xgbclassifier__eta\"] = [0.01, 0.1, 0.2]\n",
    "\n",
    "# Subsample ratio of columns when constructing each tree\n",
    "space[\"xgbclassifier__colsample_bytree\"] = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Define Search\n",
    "random_search = RandomizedSearchCV(estimator = xgb_model,\n",
    "                                   param_distributions = space,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   verbose = 10,\n",
    "                                   n_iter = 50,\n",
    "                                   random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86645987",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute Search\n",
    "results_random_xgb = random_search.fit(x_train, y_train)\n",
    "# Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
    "# CPU times: user 1min 23s, sys: 3.7 s, total: 1min 27s\n",
    "# Wall time: 1h 29min 45s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'random_all.sav'\n",
    "# pickle.dump(random_search, open(filename, 'wb'))\n",
    "\n",
    "print('Best Score: %s' % results_random_xgb.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_xgb.best_params_)\n",
    "\n",
    "# print(results_random.best_params_)\n",
    "# print(\"Randomised Search:\", results_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using RandomSearchCV\n",
    "y_pred_random = results_random_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2606cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_random)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_random)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_random)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_random)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_random)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_random)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30755",
   "metadata": {},
   "source": [
    "### Model (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b21f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(gamma = 0.1,\n",
    "                                   alpha = 0.5,\n",
    "                                   scale_pos_weight = weight_train,\n",
    "                                   objective = \"binary:logistic\",\n",
    "                                   eval_metric = \"logloss\")\n",
    "transformer = ExperimentalTransformer()\n",
    "xgb_model = make_pipeline(transformer, xgb_classifier)\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "# Maximum depth of the individual regression estimators\n",
    "grid[\"xgbclassifier__max_depth\"] = [6, 10, 15, 20, 25]\n",
    "\n",
    "# Fraction of samples to be used for fitting the individual base learners\n",
    "grid[\"xgbclassifier__subsample\"] = [0.6, 0.8, 1.0]\n",
    "\n",
    "# Step size shrinkage used in update to prevents overfitting\n",
    "grid[\"xgbclassifier__eta\"] = [0.01, 0.1, 0.2]\n",
    "\n",
    "# Subsample ratio of columns when constructing each tree\n",
    "grid[\"xgbclassifier__colsample_bytree\"] = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = grid,\n",
    "                           scoring = 'f1',\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_grid_xgb = grid_search.fit(x_train, y_train)\n",
    "# Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
    "# CPU times: user 2min 51s, sys: 15.3 s, total: 3min 6s\n",
    "# Wall time: 6h 58min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67674160",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % results_grid_xgb.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using GridSearchCV\n",
    "y_pred_grid = results_grid_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_grid)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_grid)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_grid)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_grid)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_grid)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_grid)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f95af",
   "metadata": {},
   "source": [
    "### Model (Bayesian Optimisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8551a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_hyper_pram(eta, max_depth, subsample, gamma, colsample_bytree, alpha):\n",
    "    max_depth = int(max_depth)\n",
    "    xgb_classifier = xgb.XGBClassifier(max_depth = max_depth, \n",
    "                                       eta = eta, \n",
    "                                       gamma = gamma,\n",
    "                                       subsample = subsample,\n",
    "                                       colsample_bytree = colsample_bytree,\n",
    "                                       alpha = alpha,\n",
    "                                       scale_pos_weight = weight_train,\n",
    "                                       objective = \"binary:logistic\",\n",
    "                                       eval_metric = \"logloss\")\n",
    "\n",
    "    transformer = ExperimentalTransformer()\n",
    "    xgb_model = make_pipeline(transformer, xgb_classifier)\n",
    "    \n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    y_pred = xgb_model.predict(x_test)\n",
    "    \n",
    "    return (metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_model = BayesianOptimization(xgboost_hyper_pram, \n",
    "                                   {'max_depth' : (1, 30), \n",
    "                                   'eta' : (0, 0.2), \n",
    "                                   'gamma' : (0, 1),\n",
    "                                   'subsample' : (0, 1),\n",
    "                                   'colsample_bytree' : (0, 1),\n",
    "                                   'alpha' : (0, 1)},\n",
    "                                   random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "optim_model.maximize(n_iter=15, init_points=25, acq='ei')\n",
    "\n",
    "# CPU times: user 22min 42s, sys: 3.66 s, total: 22min 46s\n",
    "# Wall time: 22min 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fda226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % optim_model.max[\"target\"])\n",
    "print('Best Hyperparameters: %s' % optim_model.max['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fa2ae",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search:\", results_grid_xgb.best_score_) \n",
    "print(\"Randomised Search:\", results_random_xgb.best_score_) \n",
    "print(\"Bayesian Optimisation:\", optim_model.max[\"target\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88861a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by bayesian optimisation)\n",
    "# params = grid_search.best_params_\n",
    "params_xgb = optim_model.max['params']\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth = int(params_xgb['max_depth']), \n",
    "                                   eta = params_xgb['eta'], \n",
    "                                   gamma = params_xgb['gamma'],\n",
    "                                   subsample = params_xgb['subsample'],\n",
    "                                   colsample_bytree = params_xgb['colsample_bytree'],\n",
    "                                   alpha = params_xgb['alpha'],\n",
    "                                   scale_pos_weight = weight_train,\n",
    "                                   objective = \"binary:logistic\",\n",
    "                                   eval_metric = \"logloss\")\n",
    "\n",
    "transformer = ExperimentalTransformer()\n",
    "xgb_model_pipeline = make_pipeline(transformer, xgb_classifier)\n",
    "xgb_model = xgb_model_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_optimal = xgb_model.predict(x_test)\n",
    "# y_pred_prob_optimal = xgb_model.predict_proba(x_test)\n",
    "# y_pred_optimal = np.zeros(y_pred_prob_optimal[:, 1].shape)\n",
    "# y_pred_optimal[y_pred_prob_optimal[:, 1] > 0.35] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ccb49",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35825edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(xgb_model.named_steps[\"xgbclassifier\"], importance_type = 'gain', height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70423b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Level\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(xgb_model.named_steps[\"xgbclassifier\"], x_train, model_output=\"probability\")\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "shap.force_plot(explainer.expected_value, shap_values[1,:], feature_names = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Level\n",
    "shap.summary_plot(shap_values, feature_names = x_test.columns, plot_type = \"bar\", sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bcfd6",
   "metadata": {},
   "source": [
    "### Final Model Selected (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_final = dataset['isFraud'].value_counts()[0] / dataset['isFraud'].value_counts()[1]\n",
    "\n",
    "# params_xgb = optim_model.max['params']\n",
    "# xgb_classifier = xgb.XGBClassifier(max_depth = int(params_xgb['max_depth']), \n",
    "#                                    eta = params_xgb['eta'], \n",
    "#                                    gamma = params_xgb['gamma'],\n",
    "#                                    subsample = params_xgb['subsample'],\n",
    "#                                    colsample_bytree = params_xgb['colsample_bytree'],\n",
    "#                                    alpha = params_xgb['alpha'],\n",
    "#                                    scale_pos_weight = weight_final,\n",
    "#                                    objective = \"binary:logistic\",\n",
    "#                                    eval_metric = \"logloss\")\n",
    "\n",
    "# transformer = ExperimentalTransformer()\n",
    "# xgb_final_model_pipeline = make_pipeline(transformer, xgb_classifier)\n",
    "\n",
    "# xgb_final_model = xgb_final_model_pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,18))\n",
    "# xgb.plot_importance(xgb_final_model.named_steps[\"xgbclassifier\"], importance_type = 'gain', height=0.8, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d0ac9",
   "metadata": {},
   "source": [
    "## 04 Support Vector Machine\n",
    "* Model (Random Search + Grid Search)\n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c641c483",
   "metadata": {},
   "source": [
    "### Model: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ab427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "svm_classifier = SVC()\n",
    "transformer = ExperimentalTransformer()\n",
    "svm_model = make_pipeline(transformer, svm_classifier)\n",
    "\n",
    "space = dict()\n",
    "\n",
    "# Kernel type to be used in the algorithm\n",
    "space[\"svc__kernel\"] = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Degree of the polynomial kernel function\n",
    "space[\"svc__degree\"] = [1, 3, 8]\n",
    "\n",
    "# Kernel coefficient for â€˜rbfâ€™, â€˜polyâ€™ and â€˜sigmoidâ€™\n",
    "space[\"svc__gamma\"] = ['scale', 'auto']\n",
    "\n",
    "# Regularisation parameter\n",
    "space[\"svc__C\"] = [0.1, 1, 10, 100]\n",
    "\n",
    "# Enable verbose output\n",
    "space[\"svc__verbose\"] = [True, False]\n",
    "\n",
    "# Define search\n",
    "random_search = RandomizedSearchCV(svm_model, \n",
    "                                   space, \n",
    "                                   cv = 5, \n",
    "                                   scoring = 'f1',\n",
    "                                   verbose = 2, \n",
    "                                   random_state = 123, \n",
    "                                   n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6de847",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_random_svm = random_search.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa337ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# filename = '04 SVM (Random).sav'\n",
    "# pickle.dump(results_random, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# results_random = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "print('Best Score: %s' % results_random_svm.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_random_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using RandomSearchCV\n",
    "y_pred_random = results_random_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d653d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_random)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_random)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_random)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_random)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_random)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_random)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41db33",
   "metadata": {},
   "source": [
    "### Model: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "svm_classifier = SVC()\n",
    "transformer = ExperimentalTransformer()\n",
    "svm_model = make_pipeline(transformer, svm_classifier)\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "# Kernel type to be used in the algorithm\n",
    "grid[\"svc__kernel\"] = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Degree of the polynomial kernel function\n",
    "grid[\"svc__degree\"] = [1, 3, 8]\n",
    "\n",
    "# Kernel coefficient for â€˜rbfâ€™, â€˜polyâ€™ and â€˜sigmoidâ€™\n",
    "grid[\"svc__gamma\"] = ['scale', 'auto']\n",
    "\n",
    "# Regularisation parameter\n",
    "grid[\"svc__C\"] = [0.1, 1, 10, 100]\n",
    "\n",
    "# Enable verbose output\n",
    "grid[\"svc__verbose\"] = [True, False]\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(svm_model, \n",
    "                      grid, \n",
    "                      scoring = 'f1',\n",
    "                      cv = 5, \n",
    "                      n_jobs = -1, \n",
    "                      verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Execute search\n",
    "results_grid_svm = search.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda90380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# filename = '04 SVM (Grid).sav'\n",
    "# pickle.dump(results_grid, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# results_grid = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "print('Best Score: %s' % results_grid_svm.best_score_)\n",
    "print('Best Hyperparameters: %s' % results_grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model using GridSearchCV\n",
    "y_pred_grid = results_grid_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_grid)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_grid)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_grid)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_grid)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_grid)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_grid)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db31f44",
   "metadata": {},
   "source": [
    "### Model: Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search:\", results_grid_svm.best_score_) \n",
    "print(\"Randomised Search:\", results_random_svm.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (initialise the object based on parameters selected by )\n",
    "# random_state = 123\n",
    "params_svm = results_grid_svm.best_params_\n",
    "\n",
    "svm_classifier = SVC(C = params_svm[\"svc__C\"], \n",
    "                     degree = params_svm[\"svc__degree\"], \n",
    "                     gamma = params_svm[\"svc__gamma\"], \n",
    "                     kernel = params_svm[\"svc__kernel\"], \n",
    "                     verbose = params_svm[\"svc__verbose\"], \n",
    "                     random_state = 123)\n",
    "\n",
    "transformer = ExperimentalTransformer()\n",
    "svm_model_pipeline = make_pipeline(transformer, svm_classifier)\n",
    "svm_model = svm_model_pipeline.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "# Save the model to disk\n",
    "# filename = '04 SVM (Optimal).sav'\n",
    "# pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# rf_regression = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b950d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_optimal = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d7608",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "* Cannot find cause black box model unless use SHAP or perm importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfe153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# x_test_imps = svm_model.named_steps[\"experimentaltransformer\"].transform(x_test)\n",
    "# imps = permutation_importance(svm_model.named_steps[\"svc\"], x_test, y_test, random_state=123)\n",
    "# feature = pd.DataFrame(imps.importances_mean, svm_model.named_steps[\"experimentaltransformer\"].columns.T, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "# feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_chart(feature, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dbab98",
   "metadata": {},
   "source": [
    "## 05 Naive Bayes\n",
    "* Model (Random Search + Grid Search)\n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da5a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bin_train = x_train[[\"protected\",\n",
    "               \"verified\", \n",
    "               \"location\", \n",
    "               \"un_special_char\", \n",
    "               \"un_uppercase\", \n",
    "               \"name_special_char\", \n",
    "               \"name_uppercase\", \n",
    "               \"des_external_links\", \n",
    "               \"has_description\"]]\n",
    "\n",
    "x_bin_test = x_test[[\"protected\",\n",
    "               \"verified\", \n",
    "               \"location\", \n",
    "               \"un_special_char\", \n",
    "               \"un_uppercase\", \n",
    "               \"name_special_char\", \n",
    "               \"name_uppercase\", \n",
    "               \"des_external_links\", \n",
    "               \"has_description\"]]\n",
    "\n",
    "x_num_train = x_train[[\"followers_count\", \n",
    "                 \"following_count\", \n",
    "                 \"tweet_count\", \n",
    "                 \"un_no_of_char\", \n",
    "                 \"name_no_of_char\", \n",
    "                 \"des_no_of_usertags\", \n",
    "                 \"des_no_of_hashtags\", \n",
    "                 \"account_age_in_days\"]]\n",
    "\n",
    "x_num_test = x_test[[\"followers_count\", \n",
    "                 \"following_count\", \n",
    "                 \"tweet_count\", \n",
    "                 \"un_no_of_char\", \n",
    "                 \"name_no_of_char\", \n",
    "                 \"des_no_of_usertags\", \n",
    "                 \"des_no_of_hashtags\", \n",
    "                 \"account_age_in_days\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040afd0",
   "metadata": {},
   "source": [
    "### Model (Random)\n",
    "* GaussianNB\n",
    "* BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f3f7e",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef683aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (GaussianNB)\n",
    "gnb_classifier = GaussianNB()\n",
    "transformer = ExperimentalTransformer()\n",
    "gnb_model = make_pipeline(transformer, gnb_classifier)\n",
    "\n",
    "space = dict()\n",
    "\n",
    "# \n",
    "space[\"gaussiannb__var_smoothing\"] = np.logspace(0,-9, num=200) \n",
    "    \n",
    "random_search = RandomizedSearchCV(estimator = gnb_model,\n",
    "                                   param_distributions = space,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   verbose = 10,\n",
    "                                   n_iter = 50,\n",
    "                                   random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_random_gnb = random_search.fit(x_num_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cedfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result_random_gnb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_random_gnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random_gnb = result_random_gnb.predict(x_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_random_gnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_random_gnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_random_gnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_random_gnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_random_gnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_random_gnb)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8325ff",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (BernoulliNB)\n",
    "bnb_classifier = BernoulliNB()\n",
    "scaler = StandardScaler()\n",
    "bnb_model = make_pipeline(scaler, bnb_classifier)\n",
    "\n",
    "space = dict()\n",
    "\n",
    "# \n",
    "space[\"bernoullinb__alpha\"] = [0, 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01]\n",
    "    \n",
    "random_search = RandomizedSearchCV(estimator = bnb_model,\n",
    "                                   param_distributions = space,\n",
    "                                   scoring = 'f1',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = 5,\n",
    "                                   verbose = 10,\n",
    "                                   n_iter = 50,\n",
    "                                   random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d23c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_random_bnb = random_search.fit(x_bin_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aef618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result_random_bnb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_random_bnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc93112",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random_bnb = result_random_bnb.predict(x_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_random_bnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_random_bnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_random_bnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_random_bnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_random_bnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_random_bnb)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34264c",
   "metadata": {},
   "source": [
    "### Model (Grid)\n",
    "* GaussianNB\n",
    "* BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9007add",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (GaussianNB)\n",
    "gnb_classifier = GaussianNB()\n",
    "transformer = ExperimentalTransformer()\n",
    "gnb_model = make_pipeline(transformer, gnb_classifier)\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "# \n",
    "grid[\"gaussiannb__var_smoothing\"] = np.logspace(0,-9, num=200) \n",
    "    \n",
    "grid_search = GridSearchCV(estimator = gnb_model,\n",
    "                           param_grid = grid,\n",
    "                           scoring = 'f1',\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_grid_gnb = grid_search.fit(x_num_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result_grid_gnb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_grid_gnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid_gnb = result_grid_gnb.predict(x_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_grid_gnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_grid_gnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_grid_gnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_grid_gnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_grid_gnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_grid_gnb)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951766c",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e87889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (BernoulliNB)\n",
    "bnb_classifier = BernoulliNB()\n",
    "scaler = StandardScaler()\n",
    "bnb_model = make_pipeline(scaler, bnb_classifier)\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "# \n",
    "grid[\"bernoullinb__alpha\"] = [0, 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01]\n",
    "    \n",
    "grid_search = GridSearchCV(estimator = bnb_model,\n",
    "                           param_grid = grid,\n",
    "                           scoring = 'f1',\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_grid_bnb = grid_search.fit(x_bin_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e522c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result_grid_bnb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_grid_bnb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed03044",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid_bnb = result_grid_bnb.predict(x_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_grid_bnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_grid_bnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_grid_bnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_grid_bnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_grid_bnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_grid_bnb)\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16489f3",
   "metadata": {},
   "source": [
    "### Model (Optimal Hyperparameters)\n",
    "* GaussianNB\n",
    "* BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d48d4d",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f79a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search (GNB):\", result_grid_gnb.best_score_) \n",
    "print(\"Randomised Search (GNB):\", result_random_gnb.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f313ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "params_gnb = result_grid_gnb.best_params_\n",
    "\n",
    "gnb_classifier = GaussianNB(var_smoothing = params_gnb[\"gaussiannb__var_smoothing\"])\n",
    "transformer = ExperimentalTransformer()\n",
    "gnb_model_pipeline = make_pipeline(transformer, gnb_classifier)\n",
    "gnb_model = gnb_model_pipeline.fit(x_num_train, np.ravel(y_train))\n",
    "\n",
    "# Save the model to disk\n",
    "# filename = '04 SVM (Optimal).sav'\n",
    "# pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# rf_regression = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_optimal_gnb = gnb_model.predict(x_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal_gnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal_gnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal_gnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal_gnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal_gnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal_gnb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal_gnb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e4e4e",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid Search (BNB):\", result_grid_bnb.best_score_) \n",
    "print(\"Randomised Search (BNB):\", result_random_bnb.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "params_bnb = result_grid_bnb.best_params_\n",
    "\n",
    "bnb_classifier = BernoulliNB(alpha = params_bnb[\"bernoullinb__alpha\"])\n",
    "scaler = StandardScaler()\n",
    "bnb_model_pipeline = make_pipeline(scaler, bnb_classifier)\n",
    "bnb_model = bnb_model_pipeline.fit(x_bin_train, np.ravel(y_train))\n",
    "\n",
    "# Save the model to disk\n",
    "# filename = '04 SVM (Optimal).sav'\n",
    "# pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model from disk\n",
    "# rf_regression = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94261101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_optimal_bnb = bnb_model.predict(x_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70063597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_optimal_bnb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_optimal_bnb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_optimal_bnb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_optimal_bnb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_optimal_bnb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_optimal_bnb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_optimal_bnb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677deab9",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8b670",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# x_test_imps = gnb_model.named_steps[\"experimentaltransformer\"].transform(x_num_test)\n",
    "imps = permutation_importance(gnb_model.named_steps[\"gaussiannb\"], x_num_test, y_test, random_state=123)\n",
    "feature = pd.DataFrame(imps.importances_mean, gnb_model.named_steps[\"experimentaltransformer\"].columns.T, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_chart(feature, \"GaussianNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1b653",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72617158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# x_test_imps = bnb_model.named_steps[\"experimentaltransformer\"].transform(x_bin_test)\n",
    "imps = permutation_importance(bnb_model.named_steps[\"bernoullinb\"], x_bin_test, y_test, random_state=123)\n",
    "feature = pd.DataFrame(imps.importances_mean, x_bin_test.columns.T, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269034ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_chart(feature, \"BernoulliNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49bb99",
   "metadata": {},
   "source": [
    "## 06 Ensemble Model\n",
    "* Model (Random Search + Grid Search)\n",
    "* Error Metrics\n",
    "* Plot for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d044cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert after getting optimal hyperparameters!!!!!\n",
    "params_rf = results_grid_rf.best_params_\n",
    "params_xgb = optim_model.max['params']\n",
    "params_svm = results_grid_svm.best_params_\n",
    "\n",
    "rf_classifier = RandomForestClassifier(bootstrap = params_rf[\"randomforestclassifier__bootstrap\"], \n",
    "                                       max_depth = params_rf[\"randomforestclassifier__max_depth\"], \n",
    "                                       max_features = params_rf[\"randomforestclassifier__max_features\"], \n",
    "                                       min_samples_split = params_rf[\"randomforestclassifier__min_samples_split\"], \n",
    "                                       n_estimators = params_rf[\"randomforestclassifier__n_estimators\"])\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth = int(params_xgb['max_depth']), \n",
    "                                   eta = params_xgb['eta'], \n",
    "                                   gamma = params_xgb['gamma'],\n",
    "                                   subsample = params_xgb['subsample'],\n",
    "                                   colsample_bytree = params_xgb['colsample_bytree'],\n",
    "                                   alpha = params_xgb['alpha'],\n",
    "                                   scale_pos_weight = weight_train,\n",
    "                                   objective = \"binary:logistic\",\n",
    "                                   eval_metric = \"logloss\")\n",
    "\n",
    "svm_classifier = SVC(C = params_svm[\"svc__C\"], \n",
    "                     degree = params_svm[\"svc__degree\"], \n",
    "                     gamma = params_svm[\"svc__gamma\"], \n",
    "                     kernel = params_svm[\"svc__kernel\"], \n",
    "                     verbose = params_svm[\"svc__verbose\"], \n",
    "                     random_state = 123)\n",
    "\n",
    "log_regression = LogisticRegression()\n",
    "\n",
    "transformer = ExperimentalTransformer()\n",
    "rf_model_pipeline = make_pipeline(transformer, rf_classifier)\n",
    "xgb_model_pipeline = make_pipeline(transformer, xgb_classifier)\n",
    "svm_model_pipeline = make_pipeline(transformer, svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba08fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = [rf_model_pipeline, xgb_model_pipeline, svm_model_pipeline]\n",
    "clf = [rf_model_pipeline, xgb_model_pipeline]\n",
    "\n",
    "for algo in clf:\n",
    "    score = cross_val_score(algo, x_test, y_test, cv = 7, scoring = 'f1')\n",
    "    print(\"The f1 score of {} is:\".format(algo),score.mean())\n",
    "\n",
    "# clf = [('rfc', rf_model_pipeline), ('xgb', xgb_model_pipeline), ('svm', svm_model_pipeline)] #list of (str, estimator)\n",
    "clf = [('rfc', rf_model_pipeline), ('xgb', xgb_model_pipeline)] #list of (str, estimator)\n",
    "\n",
    "stack_model_pipeline = StackingClassifier(estimators = clf, final_estimator = log_regression)\n",
    "score = cross_val_score(stack_model_pipeline, x_test, y_test, cv = 7, scoring = 'f1')\n",
    "print(score)\n",
    "print(\"The f1 score of is:\", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "stack_model = stack_model_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stack_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_stack)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test, y_pred_stack)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_stack)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test, y_pred_stack)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test, y_pred_stack)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test, y_pred_stack)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test, y_pred_stack)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fd72d",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_imps = stack_model.transform(x_test)\n",
    "\n",
    "rf_class = stack_model.estimators_[0].named_steps[\"randomforestclassifier\"]\n",
    "xgb_class = stack_model.estimators_[1].named_steps[\"xgbclassifier\"]\n",
    "# svm_class = stack_model.estimators_[2].named_steps[\"svc\"]\n",
    "\n",
    "rf_imps = permutation_importance(rf_class, x_test_imps, y_test, random_state=123)\n",
    "xgb_imps = permutation_importance(xgb_class, x_test_imps, y_test, random_state=123)\n",
    "# svm_imps = permutation_importance(svm_class, x_test_imps, y_test, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_xgb_imps = np.add(rf_imps.importances_mean, xgb_imps.importances_mean)\n",
    "# rf_xgb_svm_imps = np.add(rf_xgb_imps, svm_imps.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature = pd.DataFrame(rf_xgb_imps, x_test_imps.columns.T, columns=['Feature Importance']).sort_values(by='Feature Importance', ascending=False)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_chart(feature, \"Ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb57304",
   "metadata": {},
   "source": [
    "## Saving Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '01 Log Regression.sav'\n",
    "pickle.dump(log_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '02 Random Forest (grid).sav'\n",
    "pickle.dump(results_grid_rf, open(filename, 'wb'))\n",
    "\n",
    "filename = '02 Random Forest (random).sav'\n",
    "pickle.dump(results_random_rf, open(filename, 'wb'))\n",
    "\n",
    "filename = '02 Random Forest (optimal).sav'\n",
    "pickle.dump(rf_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '03 XGBoost (grid).sav'\n",
    "pickle.dump(results_grid_xgb, open(filename, 'wb'))\n",
    "\n",
    "filename = '03 XGBoost (random).sav'\n",
    "pickle.dump(results_random_xgb, open(filename, 'wb'))\n",
    "\n",
    "filename = '03 XGBoost (optimal).sav'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))\n",
    "\n",
    "# filename = '03 XGBoost (final).sav'\n",
    "# pickle.dump(xgb_final_model, open(filename, 'wb'))\n",
    "\n",
    "# filename = 'shap.sav'\n",
    "# pickle.dump(explainer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '04 SVM (grid).sav'\n",
    "pickle.dump(results_grid_svm, open(filename, 'wb'))\n",
    "\n",
    "filename = '04 SVM (random).sav'\n",
    "pickle.dump(results_random_svm, open(filename, 'wb'))\n",
    "\n",
    "filename = '04 SVM (optimal).sav'\n",
    "pickle.dump(svm_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fe987",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '05 Gaussian NB (grid).sav'\n",
    "pickle.dump(result_grid_gnb, open(filename, 'wb'))\n",
    "\n",
    "filename = '05 Gaussian NB (random).sav'\n",
    "pickle.dump(result_random_gnb, open(filename, 'wb'))\n",
    "\n",
    "filename = '05 Gaussian NB (optimal).sav'\n",
    "pickle.dump(gnb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '05 Bernoulli NB (grid).sav'\n",
    "pickle.dump(result_grid_bnb, open(filename, 'wb'))\n",
    "\n",
    "filename = '05 Bernoulli NB (random).sav'\n",
    "pickle.dump(result_random_bnb, open(filename, 'wb'))\n",
    "\n",
    "filename = '05 Bernoulli NB (optimal).sav'\n",
    "pickle.dump(bnb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '06 Ensemble.sav'\n",
    "pickle.dump(stack_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d523f",
   "metadata": {},
   "source": [
    "### Slicing Based Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc528ec",
   "metadata": {},
   "source": [
    "##### Slicing based on Verification - XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe6a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Verified Accounts: 7284\n",
      "Number of Verified Accounts: 28414\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Verified Accounts: \" + str(len(dataset[dataset['verified'] == 1].index)))\n",
    "print(\"Number of Verified Accounts: \" + str(len(dataset[dataset['verified'] == 0].index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba755988",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_accounts_dataset = dataset[dataset['verified'] == 1]\n",
    "non_verified_accounts_dataset = dataset[dataset['verified'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80efd5e",
   "metadata": {},
   "source": [
    "Training for verified accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab0fe73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (5827, 17) (5827,)\n",
      "Test set: (1457, 17) (1457,)\n"
     ]
    }
   ],
   "source": [
    "# Getting X and y\n",
    "x_verified = verified_accounts_dataset.drop(columns = ['isFraud'])\n",
    "y_verified = verified_accounts_dataset['isFraud']\n",
    "\n",
    "# Split into training and testing sets before scaling the variables and performing one hot encoding to avoid data leakage\n",
    "x_train_verified, x_test_verified, y_train_verified, y_test_verified = train_test_split(x_verified, y_verified, test_size = 0.2, random_state=101)\n",
    "print(\"Train set:\", x_train_verified.shape, y_train_verified.shape)\n",
    "print(\"Test set:\", x_test_verified.shape, y_test_verified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "027142f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load optimal XGBoost model\n",
    "xgb_regression = pickle.load(open('03 XGBoost (optimal).sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9b2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_verified_xgb = xgb_regression.predict(x_test_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3675277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9718599862731641\n",
      "Log Loss: 0.9719232882523199\n",
      "ROC AUC: 0.7066147214854112\n",
      "F1-score: 0.568421052631579\n",
      "Precision: 0.9\n",
      "Recall: 0.4153846153846154\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1392\n",
      "           1       0.90      0.42      0.57        65\n",
      "\n",
      "    accuracy                           0.97      1457\n",
      "   macro avg       0.94      0.71      0.78      1457\n",
      "weighted avg       0.97      0.97      0.97      1457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_verified, y_pred_verified_xgb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03cf3275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (22731, 17) (22731,)\n",
      "Test set: (5683, 17) (5683,)\n"
     ]
    }
   ],
   "source": [
    "# Getting X and y\n",
    "x_non_verified = non_verified_accounts_dataset.drop(columns = ['isFraud'])\n",
    "y_non_verified = non_verified_accounts_dataset['isFraud']\n",
    "\n",
    "# Split into training and testing sets before scaling the variables and performing one hot encoding to avoid data leakage\n",
    "x_train_non_verified, x_test_non_verified, y_train_non_verified, y_test_non_verified = train_test_split(x_non_verified, y_non_verified, test_size = 0.2, random_state=101)\n",
    "print(\"Train set:\", x_train_non_verified.shape, y_train_non_verified.shape)\n",
    "print(\"Test set:\", x_test_non_verified.shape, y_test_non_verified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "671cf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_non_verified_xgb = xgb_regression.predict(x_test_non_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7792b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8861516804504663\n",
      "Log Loss: 3.932231881715607\n",
      "ROC AUC: 0.8843548619229731\n",
      "F1-score: 0.8621938232161874\n",
      "Precision: 0.8500629987400252\n",
      "Recall: 0.874675885911841\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      3369\n",
      "           1       0.85      0.87      0.86      2314\n",
      "\n",
      "    accuracy                           0.89      5683\n",
      "   macro avg       0.88      0.88      0.88      5683\n",
      "weighted avg       0.89      0.89      0.89      5683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_non_verified, y_pred_non_verified_xgb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64f5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load optimal RF model\n",
    "rf_regression = pickle.load(open('02 Random Forest (optimal).sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3dbbd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_verified_rf = rf_regression.predict(x_test_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74e9dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9869595058339052\n",
      "Log Loss: 0.4504038096761597\n",
      "ROC AUC: 0.8685123784261716\n",
      "F1-score: 0.8347826086956522\n",
      "Precision: 0.96\n",
      "Recall: 0.7384615384615385\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1392\n",
      "           1       0.96      0.74      0.83        65\n",
      "\n",
      "    accuracy                           0.99      1457\n",
      "   macro avg       0.97      0.87      0.91      1457\n",
      "weighted avg       0.99      0.99      0.99      1457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_verified, y_pred_verified_rf)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_verified, y_pred_verified_rf)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_verified, y_pred_verified_rf)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_verified, y_pred_verified_rf)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_verified, y_pred_verified_rf)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_verified, y_pred_verified_rf)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_verified, y_pred_verified_rf)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6c7073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_non_verified_rf = rf_regression.predict(x_test_non_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "233c609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.960232271687489\n",
      "Log Loss: 1.3735413389087694\n",
      "ROC AUC: 0.9572565767549109\n",
      "F1-score: 0.9506765604539502\n",
      "Precision: 0.9603174603174603\n",
      "Recall: 0.9412273120138289\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      3369\n",
      "           1       0.96      0.94      0.95      2314\n",
      "\n",
      "    accuracy                           0.96      5683\n",
      "   macro avg       0.96      0.96      0.96      5683\n",
      "weighted avg       0.96      0.96      0.96      5683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_non_verified, y_pred_non_verified_rf)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3ffe0",
   "metadata": {},
   "source": [
    "##### Slicing based on Follower Count - Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6ff227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Quartile: 10584\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = plt.hist(dataset['followers_count'], bins=50)\n",
    "print(\"Upper Quartile: \" + str(int(dataset['followers_count'].describe()['75%'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3026e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_followers_dataset = dataset[dataset['followers_count'] > 10584]\n",
    "low_followers_dataset = dataset[dataset['followers_count'] <= 10584]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd61c29",
   "metadata": {},
   "source": [
    "Training for High Follower Count accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c604bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (7140, 17) (7140,)\n",
      "Test set: (1785, 17) (1785,)\n"
     ]
    }
   ],
   "source": [
    "# Getting X and y\n",
    "x_high = high_followers_dataset.drop(columns = ['isFraud'])\n",
    "y_high = high_followers_dataset['isFraud']\n",
    "\n",
    "# Split into training and testing sets before scaling the variables and performing one hot encoding to avoid data leakage\n",
    "x_train_high, x_test_high, y_train_high, y_test_high = train_test_split(x_high, y_high, test_size = 0.2, random_state=101)\n",
    "print(\"Train set:\", x_train_high.shape, y_train_high.shape)\n",
    "print(\"Test set:\", x_test_high.shape, y_test_high.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c456175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load optimal RF model\n",
    "rf_regression = pickle.load(open('02 Random Forest (optimal).sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9ebd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model (initialise the object based on parameters selected by grid search)\n",
    "# params_rf = rf_regression.best_params_\n",
    "\n",
    "# rf_classifier = RandomForestClassifier(bootstrap = params_rf[\"randomforestclassifier__bootstrap\"], \n",
    "#                                        max_depth = params_rf[\"randomforestclassifier__max_depth\"], \n",
    "#                                        max_features = params_rf[\"randomforestclassifier__max_features\"], \n",
    "#                                        min_samples_split = params_rf[\"randomforestclassifier__min_samples_split\"], \n",
    "#                                        n_estimators = params_rf[\"randomforestclassifier__n_estimators\"])\n",
    "\n",
    "# transformer = ExperimentalTransformer()\n",
    "# rf_model_pipeline = make_pipeline(transformer, rf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5c9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_rf_model = rf_model_pipeline.fit(x_train_high, np.ravel(y_train_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b72bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_high_rf = rf_regression.predict(x_test_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e75934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9781512605042016\n",
      "Log Loss: 0.7546305197710022\n",
      "ROC AUC: 0.9075986738857502\n",
      "F1-score: 0.8895184135977336\n",
      "Precision: 0.9751552795031055\n",
      "Recall: 0.8177083333333334\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1593\n",
      "           1       0.98      0.82      0.89       192\n",
      "\n",
      "    accuracy                           0.98      1785\n",
      "   macro avg       0.98      0.91      0.94      1785\n",
      "weighted avg       0.98      0.98      0.98      1785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_high, y_pred_high_rf)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_high, y_pred_high_rf)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_high, y_pred_high_rf)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_high, y_pred_high_rf)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_high, y_pred_high_rf)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_high, y_pred_high_rf)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_high, y_pred_high_rf)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb9587",
   "metadata": {},
   "source": [
    "Training for Low Follower Count accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a76312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (21418, 17) (21418,)\n",
      "Test set: (5355, 17) (5355,)\n"
     ]
    }
   ],
   "source": [
    "# Getting X and y\n",
    "x_low = low_followers_dataset.drop(columns = ['isFraud'])\n",
    "y_low = low_followers_dataset['isFraud']\n",
    "\n",
    "# Split into training and testing sets before scaling the variables and performing one hot encoding to avoid data leakage\n",
    "x_train_low, x_test_low, y_train_low, y_test_low = train_test_split(x_low, y_low, test_size = 0.2, random_state=101)\n",
    "print(\"Train set:\", x_train_low.shape, y_train_low.shape)\n",
    "print(\"Test set:\", x_test_low.shape, y_test_low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5300061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_low_rf = rf_regression.predict(x_test_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91e44971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9648926237161531\n",
      "Log Loss: 1.2125756742621112\n",
      "ROC AUC: 0.9618778243419775\n",
      "F1-score: 0.9568609453877925\n",
      "Precision: 0.9693165969316597\n",
      "Recall: 0.9447213411871318\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3148\n",
      "           1       0.97      0.94      0.96      2207\n",
      "\n",
      "    accuracy                           0.96      5355\n",
      "   macro avg       0.97      0.96      0.96      5355\n",
      "weighted avg       0.96      0.96      0.96      5355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_low, y_pred_low_rf)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_low, y_pred_low_rf)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_low, y_pred_low_rf)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_low, y_pred_low_rf)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_low, y_pred_low_rf)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_low, y_pred_low_rf)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_low, y_pred_low_rf)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74f256af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load optimal XGB model\n",
    "xgb_regression = pickle.load(open('03 XGBoost (optimal).sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7be8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_high_xgb = xgb_regression.predict(x_test_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cacb35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9518207282913165\n",
      "Log Loss: 1.664061155583229\n",
      "ROC AUC: 0.8172669491525424\n",
      "F1-score: 0.7425149700598803\n",
      "Precision: 0.8732394366197183\n",
      "Recall: 0.6458333333333334\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1593\n",
      "           1       0.87      0.65      0.74       192\n",
      "\n",
      "    accuracy                           0.95      1785\n",
      "   macro avg       0.92      0.82      0.86      1785\n",
      "weighted avg       0.95      0.95      0.95      1785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_high, y_pred_high_xgb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_high, y_pred_high_xgb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_high, y_pred_high_xgb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_high, y_pred_high_xgb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_high, y_pred_high_xgb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_high, y_pred_high_xgb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_high, y_pred_high_xgb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55dec3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prediction for the best model\n",
    "y_pred_low_xgb = xgb_regression.predict(x_test_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c102fac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8965452847805789\n",
      "Log Loss: 3.5732433247474193\n",
      "ROC AUC: 0.8944679168568993\n",
      "F1-score: 0.8755056179775281\n",
      "Precision: 0.8684797146678556\n",
      "Recall: 0.8826461259628455\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3148\n",
      "           1       0.87      0.88      0.88      2207\n",
      "\n",
      "    accuracy                           0.90      5355\n",
      "   macro avg       0.89      0.89      0.89      5355\n",
      "weighted avg       0.90      0.90      0.90      5355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error Metrics\n",
    "accuracy = metrics.accuracy_score(y_test_low, y_pred_low_xgb)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "lg_loss = metrics.log_loss(y_test_low, y_pred_low_xgb)\n",
    "print(f'Log Loss: {lg_loss}')\n",
    "roc_auc = metrics.roc_auc_score(y_test_low, y_pred_low_xgb)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "f1_score = metrics.f1_score(y_test_low, y_pred_low_xgb)\n",
    "print(f'F1-score: {f1_score}')\n",
    "precision = metrics.precision_score(y_test_low, y_pred_low_xgb)\n",
    "print(f'Precision: {precision}')\n",
    "recall = metrics.recall_score(y_test_low, y_pred_low_xgb)\n",
    "print(f'Recall: {recall}')\n",
    "report = metrics.classification_report(y_test_low, y_pred_low_xgb)\n",
    "print(f'Classification Report: \\n {report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb74346e63f945fd6738d881e35efc32cb873ffa23b07bfe4b6ce6821c83a54a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
