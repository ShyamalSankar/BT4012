{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d61021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de7a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"twitter_human_bots_dataset.csv\")\n",
    "df_celeb = pd.read_csv(\"Top-1000-Celebrity-Twitter-Accounts.csv\")\n",
    "df_bot = pd.read_csv(\"bot_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af95e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787405734442958848</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796216118331310080</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>875949740503859204</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>756119643622735875</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464781334</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37433</th>\n",
       "      <td>63963107</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37434</th>\n",
       "      <td>1064042478</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37435</th>\n",
       "      <td>1089732602</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>815529979</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37437</th>\n",
       "      <td>434896892</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37438 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id account_type\n",
       "0      787405734442958848          bot\n",
       "1      796216118331310080        human\n",
       "2      875949740503859204        human\n",
       "3      756119643622735875        human\n",
       "4               464781334        human\n",
       "...                   ...          ...\n",
       "37433            63963107        human\n",
       "37434          1064042478        human\n",
       "37435          1089732602        human\n",
       "37436           815529979        human\n",
       "37437           434896892          bot\n",
       "\n",
       "[37438 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c74e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, username, created_at, protected, verified, location, description, \n",
    "# public_metrics (followers_count, following_count, tweets_count)\n",
    "# id, tweets, account_type\n",
    "# CHECK\n",
    "# favourites_count, geo_enabled, statuses_count\n",
    "# average_tweets_per_day, account_age_days\n",
    "\n",
    "def get_twitter_dictionary(id_list, account_type_dict, client):\n",
    "    twitter_data = {'id':[], 'name':[], 'username':[], 'created_at':[], \n",
    "                    'protected':[], 'verified':[], 'location':[], \n",
    "                    'description':[], 'followers_count':[], 'following_count':[],\n",
    "                    'tweet_count':[], 'tweets':[], 'account_type':[]}\n",
    "\n",
    "    user_info = client.get_users(ids = id_list, user_fields=[\"created_at\", \"description\", \"entities\", \"id\", \"location\", \"name\", \"profile_image_url\", \"protected\", \"public_metrics\", \"url\", \"username\", \"verified\", \"withheld\"])\n",
    "    user_dict = dict()\n",
    "    info_list = user_info[0]\n",
    "    for each_user in info_list:\n",
    "        data = each_user.data\n",
    "        user_dict[data['id']] = data\n",
    "\n",
    "    for item in user_dict.items():\n",
    "        each_user_id = item[0]\n",
    "        each_user_account_type = account_type_dict[each_user_id]\n",
    "        each_user_info = item[1]\n",
    "        tweets = client.get_users_tweets(each_user_id, max_results = 5)\n",
    "\n",
    "        if not tweets[0]:\n",
    "            continue\n",
    "        for tweet in tweets[0]:\n",
    "            txt = tweet.text\n",
    "\n",
    "            twitter_data['id'].append(each_user_id)\n",
    "            twitter_data['tweets'].append(txt)\n",
    "            twitter_data['account_type'].append(each_user_account_type)\n",
    "            each_dictionary = user_dict[each_user_id]\n",
    "\n",
    "            if 'name' in each_dictionary:\n",
    "                twitter_data['name'].append(each_dictionary['name'])\n",
    "            else:\n",
    "                twitter_data['name'].append('')\n",
    "\n",
    "            if 'username' in each_dictionary:\n",
    "                twitter_data['username'].append(each_dictionary['username'])\n",
    "            else:\n",
    "                twitter_data['username'].append('')\n",
    "\n",
    "            if 'created_at' in each_dictionary:\n",
    "                twitter_data['created_at'].append(each_dictionary['created_at'])\n",
    "            else:\n",
    "                twitter_data['created_at'].append('')\n",
    "\n",
    "            if 'protected' in each_dictionary:\n",
    "                twitter_data['protected'].append(each_dictionary['protected'])\n",
    "            else:\n",
    "                twitter_data['protected'].append('')\n",
    "\n",
    "            if 'verified' in each_dictionary:\n",
    "                twitter_data['verified'].append(each_dictionary['verified'])\n",
    "            else:\n",
    "                twitter_data['verified'].append('')\n",
    "\n",
    "            if 'location' in each_dictionary:\n",
    "                twitter_data['location'].append(each_dictionary['location'])\n",
    "            else:\n",
    "                twitter_data['location'].append('')\n",
    "\n",
    "            if 'description' in each_dictionary:\n",
    "                twitter_data['description'].append(each_dictionary['description'])\n",
    "            else:\n",
    "                twitter_data['description'].append('')\n",
    "\n",
    "            if 'public_metrics' in each_dictionary:\n",
    "                each_pub_metric = each_dictionary['public_metrics']\n",
    "\n",
    "                if 'followers_count' in each_pub_metric:\n",
    "                    twitter_data['followers_count'].append(each_pub_metric['followers_count'])\n",
    "                else:\n",
    "                    twitter_data['followers_count'].append('')\n",
    "\n",
    "                if 'following_count' in each_pub_metric:\n",
    "                    twitter_data['following_count'].append(each_pub_metric['following_count'])\n",
    "                else:\n",
    "                    twitter_data['following_count'].append('')\n",
    "\n",
    "                if 'tweet_count' in each_pub_metric:\n",
    "                    twitter_data['tweet_count'].append(each_pub_metric['tweet_count'])\n",
    "                else:\n",
    "                    twitter_data['tweet_count'].append('')\n",
    "            else:\n",
    "                twitter_data['followers_count'].append('')\n",
    "                twitter_data['following_count'].append('')\n",
    "                twitter_data['tweet_count'].append('')\n",
    "        \n",
    "    return twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45631570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_manipulation(combined_twitter_data, pattern):\n",
    "    combined_twitter_data['url']= combined_twitter_data[\"tweets\"].str.extract(pattern, expand=True)\n",
    "\n",
    "    combined_twitter_data.loc[(combined_twitter_data['url'] != np.nan) & (combined_twitter_data[\"tweets\"].str.startswith(\"RT @\")), \n",
    "                              'is_quoted_retweets'] = 1\n",
    "\n",
    "    combined_twitter_data.loc[(combined_twitter_data['is_quoted_retweets'] != 1, 'is_quoted_retweets')] = 0\n",
    "\n",
    "    combined_twitter_data['is_quoted_retweets'] = combined_twitter_data['is_quoted_retweets'].astype(int)\n",
    "\n",
    "    combined_twitter_data = combined_twitter_data.reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return combined_twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "64142256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, username, created_at, protected, verified, location, description, \n",
    "# public_metrics (followers_count, following_count, tweets_count)\n",
    "# id, tweets, account_type\n",
    "# CHECK\n",
    "# favourites_count, geo_enabled, statuses_count\n",
    "# average_tweets_per_day, account_age_days\n",
    "\n",
    "def get_features_dictionary(id_list, account_type_dict, client):\n",
    "    twitter_data = {'id':[], 'name':[], 'username':[], 'created_at':[], \n",
    "                    'protected':[], 'verified':[], 'location':[], \n",
    "                    'description':[], 'followers_count':[], 'following_count':[],\n",
    "                    'tweet_count':[], 'account_type':[]}\n",
    "\n",
    "    user_info = client.get_users(ids = id_list, user_fields=[\"created_at\", \"description\", \"entities\", \"id\", \"location\", \"name\", \"profile_image_url\", \"protected\", \"public_metrics\", \"url\", \"username\", \"verified\", \"withheld\"])\n",
    "    user_dict = dict()\n",
    "    info_list = user_info[0]\n",
    "    if info_list == None:\n",
    "        return twitter_data\n",
    "    \n",
    "    for each_user in info_list:\n",
    "        data = each_user.data\n",
    "        user_dict[data['id']] = data\n",
    "\n",
    "    for item in user_dict.items():\n",
    "        each_user_id = item[0]\n",
    "        each_user_account_type = account_type_dict[each_user_id]\n",
    "        each_user_info = item[1]\n",
    "        tweets = client.get_users_tweets(each_user_id, max_results = 5)\n",
    "        twitter_data['id'].append(each_user_id)\n",
    "        twitter_data['account_type'].append(each_user_account_type)\n",
    "        each_dictionary = user_dict[each_user_id]\n",
    "        \n",
    "        if 'name' in each_dictionary:\n",
    "                twitter_data['name'].append(each_dictionary['name'])\n",
    "        else:\n",
    "            twitter_data['name'].append('')\n",
    "\n",
    "        if 'username' in each_dictionary:\n",
    "            twitter_data['username'].append(each_dictionary['username'])\n",
    "        else:\n",
    "            twitter_data['username'].append('')\n",
    "\n",
    "        if 'created_at' in each_dictionary:\n",
    "            twitter_data['created_at'].append(each_dictionary['created_at'])\n",
    "        else:\n",
    "            twitter_data['created_at'].append('')\n",
    "\n",
    "        if 'protected' in each_dictionary:\n",
    "            twitter_data['protected'].append(each_dictionary['protected'])\n",
    "        else:\n",
    "            twitter_data['protected'].append('')\n",
    "\n",
    "        if 'verified' in each_dictionary:\n",
    "            twitter_data['verified'].append(each_dictionary['verified'])\n",
    "        else:\n",
    "            twitter_data['verified'].append('')\n",
    "\n",
    "        if 'location' in each_dictionary:\n",
    "            twitter_data['location'].append(each_dictionary['location'])\n",
    "        else:\n",
    "            twitter_data['location'].append('')\n",
    "\n",
    "        if 'description' in each_dictionary:\n",
    "            twitter_data['description'].append(each_dictionary['description'])\n",
    "        else:\n",
    "            twitter_data['description'].append('')\n",
    "\n",
    "        if 'public_metrics' in each_dictionary:\n",
    "            each_pub_metric = each_dictionary['public_metrics']\n",
    "\n",
    "            if 'followers_count' in each_pub_metric:\n",
    "                twitter_data['followers_count'].append(each_pub_metric['followers_count'])\n",
    "            else:\n",
    "                twitter_data['followers_count'].append('')\n",
    "\n",
    "            if 'following_count' in each_pub_metric:\n",
    "                twitter_data['following_count'].append(each_pub_metric['following_count'])\n",
    "            else:\n",
    "                twitter_data['following_count'].append('')\n",
    "\n",
    "            if 'tweet_count' in each_pub_metric:\n",
    "                twitter_data['tweet_count'].append(each_pub_metric['tweet_count'])\n",
    "            else:\n",
    "                twitter_data['tweet_count'].append('')\n",
    "        else:\n",
    "            twitter_data['followers_count'].append('')\n",
    "            twitter_data['following_count'].append('')\n",
    "            twitter_data['tweet_count'].append('')\n",
    "\n",
    "    return twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e247edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 9\n",
    "pattern = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)' \n",
    "\n",
    "for each_round in range(16):\n",
    "    token = bearer_tokens[each_round%3]\n",
    "    client = tweepy.Client(bearer_token= token)\n",
    "    print(token)\n",
    "    \n",
    "    twitter_data_list = []\n",
    "    for i in range(15):\n",
    "        start = i * 100\n",
    "        end = start + 100\n",
    "        df_tweet_subset = df_tweets[start: end]\n",
    "        acc_type_dict = dict(zip(df_tweet_subset[\"id\"].astype(str), df_tweet_subset[\"account_type\"]))\n",
    "        each_id_list = list(df_tweet_subset[\"id\"])\n",
    "        print(str(start) + \" : \" + str(end)) \n",
    "        twitter_data = get_twitter_dictionary(each_id_list, acc_type_dict, client)\n",
    "        tweets_df = pd.DataFrame(twitter_data)\n",
    "        twitter_data_list.append(tweets_df)\n",
    "    \n",
    "    start_index += 1\n",
    "    \n",
    "    combined_twitter_data = pd.concat(twitter_data_list)\n",
    "    \n",
    "    combined_twitter_data = data_manipulation(combined_twitter_data, pattern)\n",
    "    \n",
    "    combined_twitter_data.to_csv(f'combined/combined_twitter_data{each_round+10}.csv')\n",
    "    \n",
    "    print(\"round\" + str(each_round+10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e9d1b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 : 1740\n"
     ]
    }
   ],
   "source": [
    "start_index = 9\n",
    "pattern = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)' \n",
    "\n",
    "client = tweepy.Client(bearer_token = bearer_token3)\n",
    "\n",
    "twitter_data_list = []\n",
    "for i in range(10):\n",
    "    start = i * 100\n",
    "    end = start + 100\n",
    "    df_tweet_subset = df_tweets_pro[start: end]\n",
    "    acc_type_dict = dict(zip(df_tweet_subset[\"id\"].astype(str), df_tweet_subset[\"account_type\"]))\n",
    "    each_id_list = list(df_tweet_subset[\"id\"])\n",
    "    print(str(start) + \" : \" + str(end)) \n",
    "    twitter_data = get_features_dictionary(each_id_list, acc_type_dict, client)\n",
    "    tweets_df = pd.DataFrame(twitter_data)\n",
    "    twitter_data_list.append(tweets_df)\n",
    "\n",
    "combined_twitter_data = pd.concat(twitter_data_list)\n",
    "\n",
    "combined_twitter_data[\"tweets\"] = \"\"\n",
    "\n",
    "combined_twitter_data.to_csv(f'combined/combined_twitter_data32.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1595434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, username, created_at, protected, verified, location, description, \n",
    "# public_metrics (followers_count, following_count, tweets_count)\n",
    "# id, tweets, account_type\n",
    "# CHECK\n",
    "# favourites_count, geo_enabled, statuses_count\n",
    "# average_tweets_per_day, account_age_days\n",
    "\n",
    "def get_user_dictionary(id_user, client):\n",
    "    twitter_data = {'id':[], 'name':[], 'username':[], 'created_at':[], \n",
    "                    'protected':[], 'verified':[], 'location':[], \n",
    "                    'description':[], 'followers_count':[], 'following_count':[],\n",
    "                    'tweet_count':[]}\n",
    "\n",
    "    \n",
    "    user = client.get_user(id=id_user,\n",
    "                                user_fields=[\"created_at\",\n",
    "                                             \"description\",\n",
    "                                             \"entities\",\n",
    "                                             \"id\",\n",
    "                                             \"location\",\n",
    "                                             \"name\",\n",
    "                                             \"profile_image_url\",\n",
    "                                             \"public_metrics\",\n",
    "                                             \"url\",\n",
    "                                             \"username\",\n",
    "                                             \"verified\", \n",
    "                                             \"protected\"])\n",
    "    user_dict = user.data\n",
    "    \n",
    "    if user_dict == None:\n",
    "        return None\n",
    "    \n",
    "    if 'id' in user_dict:\n",
    "        twitter_data['id'] = user_dict['id']\n",
    "    else:\n",
    "        twitter_data['id'] = ''\n",
    "    \n",
    "    if 'name' in user_dict:\n",
    "        twitter_data['name'] = user_dict['name']\n",
    "    else:\n",
    "        twitter_data['name'] = ''\n",
    "\n",
    "    if 'username' in user_dict:\n",
    "        twitter_data['username'] = user_dict['username']\n",
    "    else:\n",
    "        twitter_data['username'] = ''\n",
    "\n",
    "    if 'created_at' in user_dict:\n",
    "        twitter_data['created_at'] = user_dict['created_at']\n",
    "    else:\n",
    "        twitter_data['created_at'] = ''\n",
    "\n",
    "    if 'protected' in user_dict:\n",
    "        twitter_data['protected'] = user_dict['protected']\n",
    "    else:\n",
    "        twitter_data['protected'] = ''\n",
    "\n",
    "    if 'verified' in user_dict:\n",
    "        twitter_data['verified'] = user_dict['verified']\n",
    "    else:\n",
    "        twitter_data['verified'] = ''\n",
    "\n",
    "    if 'location' in user_dict:\n",
    "        twitter_data['location'] = user_dict['location']\n",
    "    else:\n",
    "        twitter_data['location'] = ''\n",
    "\n",
    "    if 'description' in user_dict:\n",
    "        twitter_data['description'] = user_dict['description']\n",
    "    else:\n",
    "        twitter_data['description'] = ''\n",
    "\n",
    "    if 'public_metrics' in user_dict:\n",
    "        each_pub_metric = user_dict['public_metrics']\n",
    "\n",
    "        if 'followers_count' in each_pub_metric:\n",
    "            twitter_data['followers_count'] = each_pub_metric['followers_count']\n",
    "        else:\n",
    "            twitter_data['followers_count'] = ''\n",
    "\n",
    "        if 'following_count' in each_pub_metric:\n",
    "            twitter_data['following_count'] = each_pub_metric['following_count']\n",
    "        else:\n",
    "            twitter_data['following_count'] = ''\n",
    "\n",
    "        if 'tweet_count' in each_pub_metric:\n",
    "            twitter_data['tweet_count'] = each_pub_metric['tweet_count']\n",
    "        else:\n",
    "            twitter_data['tweet_count'] = ''\n",
    "    else:\n",
    "        twitter_data['followers_count'] = ''\n",
    "        twitter_data['following_count'] = ''\n",
    "        twitter_data['tweet_count'] = ''\n",
    "    return twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69db66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token1 = 'AAAAAAAAAAAAAAAAAAAAADuChwEAAAAAyd5NyoPPZfk%2FiBwmc2mC9me33RA%3DTFH93ScdBzcU6OHVLLsTDHKLW599NhhPoEBTPi0KFWdAEbmFth'\n",
    "bearer_token2 = 'AAAAAAAAAAAAAAAAAAAAAAK%2FhwEAAAAAtHE4qeLy3hhb660R143d7IOccaE%3D8qaWBsRfyKMigZj2jBVVFNifngriGAkuwJv74wOOs05m6XNReW'\n",
    "bearer_token3 = 'AAAAAAAAAAAAAAAAAAAAAOjAhwEAAAAAzL7KuhOWC8yybNEnpbXPfhmCpMA%3Ds3R17rqHTA6rqR2kDhis6mrjFWYth3VgLgUu6w354BlwY2hGH8'\n",
    "\n",
    "bearer_tokens = [bearer_token3, bearer_token1, bearer_token2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1365c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 9\n",
    "pattern = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)' \n",
    "\n",
    "client = tweepy.Client(bearer_token = bearer_token3)\n",
    "\n",
    "twitter_data_list = []\n",
    "for i in range(len(df_bot)):\n",
    "    twitter_data = get_user_dictionary(df_bot[\"user_id\"][i], client)\n",
    "    if twitter_data == None:\n",
    "        continue\n",
    "    twitter_df = pd.DataFrame([twitter_data])\n",
    "    twitter_data_list.append(twitter_df)\n",
    "    \n",
    "combined_twitter_data = pd.concat(twitter_data_list)\n",
    "\n",
    "combined_twitter_data[\"tweets\"] = \"\"\n",
    "\n",
    "combined_twitter_data.to_csv(f'bot_crawled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4939",
   "metadata": {},
   "source": [
    "#### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "127c310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run from here in the future\n",
    "\n",
    "directory = os.getcwd() + \"\\combined\"\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "df_combined_list = []\n",
    "for each_file in file_list:\n",
    "    file = pd.read_csv(f'combined\\{each_file}')\n",
    "    file = file.drop(columns = ['Unnamed: 0'])\n",
    "    df_combined_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b2e17d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined = pd.concat(df_combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a7d7c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined = final_combined.reset_index(inplace = False, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dd737b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined['id'] = final_combined['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adad94d",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0acfccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35698"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_others = final_combined.drop_duplicates(subset=['id'], keep='first')\n",
    "final_combined_others = final_combined_others.drop(columns = ['is_quoted_retweets'])\n",
    "final_combined_others['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2fe35e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_TF(variable):\n",
    "    if variable == 'True':\n",
    "        return True\n",
    "    if variable == 'False':\n",
    "        return False\n",
    "    if variable == '0.0':\n",
    "        return False\n",
    "    if variable == '1.0':\n",
    "        return True\n",
    "    return variable\n",
    "\n",
    "boolean_var = [\"verified\", \"protected\"]\n",
    "\n",
    "for var in boolean_var:\n",
    "    final_combined_others[var] = final_combined_others[var].apply(convert_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e0770895",
   "metadata": {},
   "outputs": [],
   "source": [
    "others_dataset = final_combined_others.drop(columns = ['tweets'])\n",
    "others_dataset.to_csv('others_dataset.csv', index = False)\n",
    "others_dataset.to_csv('../2. Feature Engineering/others_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "18e3463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35698, 13)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537ce63",
   "metadata": {},
   "source": [
    "#### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8d7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined = final_combined[~final_combined['tweets'].str.startswith(\"RT @\")]\n",
    "final_combined = final_combined.drop(columns = ['protected', 'is_quoted_retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbbe028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset = final_combined[['id', 'tweets', 'account_type']]\n",
    "tweet_dataset.to_csv('tweet_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1051200f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88132, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f2a57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined.to_csv('final_twitter_dataset.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
